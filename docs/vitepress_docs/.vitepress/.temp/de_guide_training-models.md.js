import { ssrRenderAttrs } from "vue/server-renderer";
import { useSSRContext } from "vue";
import { _ as _export_sfc } from "./plugin-vue_export-helper.1tPrXgE0.js";
const __pageData = JSON.parse('{"title":"Training von KI-Models für Open Ticket AI","description":"Anleitung zum Trainieren oder Fine-Tuning von Models für Open Ticket AI.","frontmatter":{"title":"Training von KI-Models für Open Ticket AI","description":"Anleitung zum Trainieren oder Fine-Tuning von Models für Open Ticket AI."},"headers":[],"relativePath":"de/guide/training-models.md","filePath":"de/guide/training-models.md"}');
const _sfc_main = { name: "de/guide/training-models.md" };
function _sfc_ssrRender(_ctx, _push, _parent, _attrs, $props, $setup, $data, $options) {
  _push(`<div${ssrRenderAttrs(_attrs)}><h1 id="training-des-model" tabindex="-1">Training des Model <a class="header-anchor" href="#training-des-model" aria-label="Permalink to &quot;Training des Model&quot;">​</a></h1><p>:::note Sie müssen nur dann ein eigenes Model trainieren, wenn Sie ein benutzerdefiniertes Model verwenden oder die Standard-Models per Fine-Tuning anpassen möchten. Um gute Ergebnisse zu erzielen, ist eine erhebliche Menge an Trainingsdaten erforderlich – idealerweise mindestens 1000 Tickets pro Warteschlange und Priorität. Datenbereinigung, Normalisierung, Tokenisierung und das Experimentieren mit verschiedenen Models und Hyperparametern sind oft erforderlich. :::</p><p>Das Training oder Fine-Tuning eines Model für Open Ticket AI umfasst mehrere Schlüsselschritte:</p><h3 id="_1-datensammlung" tabindex="-1">1. Datensammlung <a class="header-anchor" href="#_1-datensammlung" aria-label="Permalink to &quot;1. Datensammlung&quot;">​</a></h3><ul><li><strong>Historische Daten exportieren</strong>: Sammeln Sie historische Ticketdaten (einschließlich Betreff und Text) aus Ihrem bestehenden Ticketsystem.</li><li><strong>Daten labeln</strong>: Weisen Sie jedem Ticket die korrekte Warteschlange und Priorität zu. Dieser gelabelte Datensatz bildet die Grundlage für das Training Ihres Model.</li></ul><h3 id="_2-datenbereinigung" tabindex="-1">2. Datenbereinigung <a class="header-anchor" href="#_2-datenbereinigung" aria-label="Permalink to &quot;2. Datenbereinigung&quot;">​</a></h3><ul><li><strong>Stördaten entfernen</strong>: Beseitigen Sie irrelevante Informationen wie E-Mail-Signaturen, personenbezogene Daten (PII) und Spam.</li><li><strong>Text normalisieren</strong>: Standardisieren Sie Leerräume und stellen Sie eine konsistente Zeichenkodierung sicher.</li></ul><h3 id="_3-datentransformation-tokenisierung" tabindex="-1">3. Datentransformation &amp; Tokenisierung <a class="header-anchor" href="#_3-datentransformation-tokenisierung" aria-label="Permalink to &quot;3. Datentransformation &amp; Tokenisierung&quot;">​</a></h3><ul><li><strong>Felder kombinieren</strong>: Verketten Sie den Betreff und den Text der Tickets zu einem einzigen Eingabetext für das Model.</li><li><strong><code>max_length</code> festlegen</strong>: Wählen Sie eine geeignete <code>max_length</code> für die Tokenisierung (z. B. 256–512 Tokens), basierend auf der medianen Länge Ihrer Tickets. Dies verhindert das Abschneiden wichtiger Informationen und schont gleichzeitig die Rechenressourcen.</li><li><strong>Tokenizer verwenden</strong>: Nutzen Sie den bereitgestellten <code>ticket_combined_email_tokenizer</code> oder einen Tokenizer, der mit dem von Ihnen gewählten Model kompatibel ist.</li></ul><h3 id="_4-model-auswahl-hardware" tabindex="-1">4. Model-Auswahl &amp; Hardware <a class="header-anchor" href="#_4-model-auswahl-hardware" aria-label="Permalink to &quot;4. Model-Auswahl &amp; Hardware&quot;">​</a></h3><p>Berücksichtigen Sie bei der Auswahl eines Model und der erforderlichen Hardware Folgendes:</p><table tabindex="0"><thead><tr><th>Model</th><th>Benötigter RAM</th><th>Anmerkungen</th></tr></thead><tbody><tr><td><code>distilbert-base-german-cased</code></td><td>2 GB</td><td>Leichtgewichtig, deutscher Text</td></tr><tr><td><code>bert-base-german-cased</code></td><td>4 GB</td><td>Höhere Genauigkeit, deutscher Text</td></tr><tr><td><code>deberta-large-mnli</code></td><td>8 GB</td><td>Mehrsprachig / große Kontexte</td></tr></tbody></table><p>(<em>Hinweis: Die obige Tabelle enthält Beispiele; die tatsächlichen Anforderungen können abweichen.</em>)</p><h3 id="_5-training-fine-tuning" tabindex="-1">5. Training &amp; Fine-Tuning <a class="header-anchor" href="#_5-training-fine-tuning" aria-label="Permalink to &quot;5. Training &amp; Fine-Tuning&quot;">​</a></h3><ul><li><strong>Hyperparameter-Tuning</strong>: Verwenden Sie den integrierten Hyperparameter-Tuner, um mit Einstellungen wie <code>learning_rate</code>, <code>batch_size</code> und <code>epochs</code> zu experimentieren und die optimale Konfiguration für Ihren Datensatz zu finden.</li><li><strong>Leistung überwachen</strong>: Das Trainingsskript gibt eine Zusammenfassung der Leistung und Ressourcennutzung des Model aus, die Ihnen hilft, den Fortschritt zu verfolgen und Anpassungen vorzunehmen.</li></ul><h3 id="_6-evaluierung" tabindex="-1">6. Evaluierung <a class="header-anchor" href="#_6-evaluierung" aria-label="Permalink to &quot;6. Evaluierung&quot;">​</a></h3><ul><li><strong>Genauigkeit messen</strong>: Bewerten Sie die Leistung des Model anhand seiner Genauigkeit bei der Vorhersage von Warteschlange und Priorität.</li><li><strong>Konfidenz analysieren</strong>: Untersuchen Sie die Beziehung zwischen den Konfidenzwerten des Model und der Korrektheit seiner Vorhersagen. Diese Analyse ist entscheidend für die Festlegung eines optimalen <code>confidence_threshold</code> in der Konfiguration.</li><li><strong>Confidence-Weighted Accuracy Score (CWAS)</strong> (Optional): Sie könnten die Verwendung einer Metrik wie CWAS in Betracht ziehen, um eine differenziertere Sicht auf die Leistung zu erhalten:<div class="language-math vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">math</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>\\text{CWAS} = \\text{percent_predicted} \\times (\\text{percent_correct}^2)</span></span></code></pre></div>Dieser Score belohnt Models, die sowohl genau sind als auch einen hohen Prozentsatz an Vorhersagen treffen (d. h. sich bei Fällen mit geringer Konfidenz nicht übermäßig auf einen Standardwert zurückfallen lassen).</li></ul></div>`);
}
const _sfc_setup = _sfc_main.setup;
_sfc_main.setup = (props, ctx) => {
  const ssrContext = useSSRContext();
  (ssrContext.modules || (ssrContext.modules = /* @__PURE__ */ new Set())).add("de/guide/training-models.md");
  return _sfc_setup ? _sfc_setup(props, ctx) : void 0;
};
const trainingModels = /* @__PURE__ */ _export_sfc(_sfc_main, [["ssrRender", _sfc_ssrRender]]);
export {
  __pageData,
  trainingModels as default
};
